{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_voxels(optimized_voxel, output_path):\n",
    "    voxels_src = optimized_voxel\n",
    "    # voxels_src = torch.nn.Sigmoid(voxels_src)\n",
    "    voxel_size = 32\n",
    "    max_value = 1.1\n",
    "    min_value = -1.1\n",
    "    #make vertices and faces for symmetric 360 degree rotation\n",
    "    print(voxels_src.shape)\n",
    "    vertices, faces = mcubes.marching_cubes(voxels_src.detach().cpu().squeeze().numpy(), 0.3)\n",
    "    vertices = torch.tensor(vertices).float()\n",
    "    faces = torch.tensor(faces.astype(int))\n",
    "    color1 = [0.7, 0.0, 0.4]\n",
    "    color2 = [0.6, 1.0, 1.0]\n",
    "    # Vertex coordinates are indexed by array position, so we need to\n",
    "    # renormalize the coordinate system.\n",
    "    vertices = (vertices / voxel_size) * (max_value - min_value) + min_value    \n",
    "    vertices = vertices.unsqueeze(0)  # (N_v, 3) -> (1, N_v, 3)\n",
    "    faces = faces.unsqueeze(0)\n",
    "    print(\"Shape of vertices:\", vertices.shape)\n",
    "    z_min = vertices[:,:,2].min()\n",
    "    z_max = vertices[:,:,2].max()\n",
    "    alpha = (vertices[:, :, 2] - z_min) / (z_max - z_min)\n",
    "    new_colors = alpha[:, :, None] * torch.tensor(color2) + (1 - alpha[:, :, None]) * torch.tensor(color1)\n",
    "    textures = pytorch3d.renderer.TexturesVertex(new_colors)\n",
    "    lights = pytorch3d.renderer.PointLights(location=[[0, 0.0, -3.0]], device=args.device)\n",
    "    voxel_chair_mesh = pytorch3d.structures.Meshes(verts=vertices, faces=faces, textures=textures).to(\n",
    "        args.device\n",
    "    )\n",
    "    renderer = get_mesh_renderer(image_size=512, device=args.device)\n",
    "    num_frames = 36\n",
    "    render_full = []\n",
    "    camera_positions = []\n",
    "    azim = torch.linspace(0, 360, num_frames)\n",
    "    for azi in azim:\n",
    "        azimuth = azi\n",
    "        distance = 3.0\n",
    "        elevation = 30.0\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(distance, elevation, azimuth, device=args.device, degrees=True)\n",
    "        camera_positions.append((R,T))\n",
    "    for R,T in tqdm(camera_positions):\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=args.device)\n",
    "        rend = renderer(voxel_chair_mesh, cameras=cameras, lights=lights)\n",
    "        rend = rend[0, ..., :3].cpu().numpy()  # (N, H, W, 3)\n",
    "        render_full.append(rend)\n",
    "    images = []\n",
    "    for i, r in enumerate(render_full):\n",
    "        image = Image.fromarray((r * 255).astype(np.uint8))\n",
    "        images.append(np.array(image))\n",
    "    imageio.mimsave(output_path, images, duration=12.0, loop=0)\n",
    "\n",
    "def render_points(optimized_points, output_path, type_data):\n",
    "    image_size= 512\n",
    "    background_color=(1, 1, 1)\n",
    "    renderer = get_points_renderer(\n",
    "        image_size=image_size, background_color=background_color\n",
    "    )\n",
    "    verts = optimized_points\n",
    "    rgb = (verts - verts.min()) / (verts.max() - verts.min())\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    color1 = torch.tensor([1.0, 0.0, 0.0])\n",
    "    color2 = torch.tensor([0.0,0.0, 1.0])\n",
    "    color1 = color1.to(device)\n",
    "    color2 = color2.to(device)\n",
    "    color = rgb[:, :, None] * color2 + (1 - rgb[:, :, None]) * color1\n",
    "    color=color.squeeze(0).permute(1,0,2)\n",
    "    \n",
    "    if (type_data != \"gt\"):\n",
    "        # verts = verts.unsqueeze(0)\n",
    "        print(\"Points shape: \", verts.shape)\n",
    "        print(\"RGB shape: \", color.shape)\n",
    "    point_cloud = pytorch3d.structures.Pointclouds(points=verts, features=color)\n",
    "    num_frames = 36\n",
    "    render_full = []\n",
    "    camera_positions = []\n",
    "    azim = torch.linspace(0, 360, num_frames)\n",
    "    for azi in azim:\n",
    "        azimuth = azi\n",
    "        distance = 1.0\n",
    "        elevation = 30.0\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(distance, elevation, azimuth, device=args.device, degrees=True)\n",
    "        camera_positions.append((R,T))\n",
    "    for R,T in tqdm(camera_positions):\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=args.device)\n",
    "        rend = renderer(point_cloud, cameras=cameras)\n",
    "        rend = rend[0, ..., :3].detach().cpu().numpy()  # (N, H, W, 3)\n",
    "        render_full.append(rend)\n",
    "    images = []\n",
    "    for i, r in enumerate(render_full):\n",
    "        image = Image.fromarray((r * 255).astype(np.uint8))\n",
    "        images.append(np.array(image))\n",
    "    imageio.mimsave(output_path, images, duration=12.0, loop=0)    \n",
    "    print('Done!')\n",
    "\n",
    "def render_mesh(mesh_src, args, output_file):\n",
    "    vertices = mesh_src.verts_packed().to(args.device)\n",
    "    faces = mesh_src.faces_packed().to(args.device)\n",
    "    color1 = [0.7, 0.0, 0.4]\n",
    "    color2 = [0.6, 1.0, 1.0]\n",
    "    vertices = vertices.unsqueeze(0)  # (N_v, 3) -> (1, N_v, 3)\n",
    "    faces = faces.unsqueeze(0)  # (N_f, 3) -> (1, N_f, 3)\n",
    "    z_min = vertices[:,:,2].min()\n",
    "    z_max = vertices[:,:,2].max()\n",
    "    alpha = (vertices[:, :, 2] - z_min) / (z_max - z_min)\n",
    "    new_colors = alpha[:, :, None] * torch.tensor(color2).to(args.device) + (1 - alpha[:, :, None]) * torch.tensor(color1).to(args.device)\n",
    "    textures = pytorch3d.renderer.TexturesVertex(new_colors)\n",
    "    mesh = pytorch3d.structures.Meshes(\n",
    "        verts=vertices,\n",
    "        faces=faces,\n",
    "        textures=textures\n",
    "    )\n",
    "    renderer = get_mesh_renderer(image_size=512, device=args.device)\n",
    "    lights = pytorch3d.renderer.PointLights(location=[[0.0, 0.0, -3.0]], device=args.device)\n",
    "    num_frames = 36\n",
    "    camera_positions = []\n",
    "    # output_file = \"Results/mesh.gif\"\n",
    "    azim = torch.linspace(0, 360, num_frames)\n",
    "    for azi in azim:\n",
    "        azimuth = azi\n",
    "        distance = 2.0\n",
    "        elevation = 30.0\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(distance, elevation, azimuth, device=args.device, degrees=True)\n",
    "        camera_positions.append((R,T))\n",
    "    render_full = []\n",
    "    for R,T in tqdm(camera_positions):\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=args.device)\n",
    "        rend = renderer(mesh, cameras=cameras, lights=lights)\n",
    "        rend = rend.detach().cpu().numpy()[0, ..., :3]  # (N, H, W, 3)\n",
    "        render_full.append(rend)\n",
    "    images = []\n",
    "    for i, r in enumerate(render_full):\n",
    "        image = Image.fromarray((r * 255).astype(np.uint8))\n",
    "        images.append(np.array(image))\n",
    "    imageio.mimsave(output_file, images, duration=12.0, loop=0)\n",
    "    print('Done!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    my_images = []\n",
    "    for i in range(num_frames):\n",
    "        dist = 3.0\n",
    "        elev = 0\n",
    "        azim = 360 * i / num_frames\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(dist, elev, azim, device=device)\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "        rend = renderer(point_cloud_combined, cameras=cameras)\n",
    "        rend = rend[0, ..., :3].cpu().numpy()\n",
    "        frame = Image.fromarray((rend * 255).astype(np.uint8))\n",
    "        my_images.append(np.array(frame))\n",
    "    imageio.mimsave(\"output/point_cloud_combined.gif\", my_images, fps=10)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "from model import SingleViewto3D\n",
    "from r2n2_custom import R2N2\n",
    "from  pytorch3d.datasets.r2n2.utils import collate_batched_R2N2\n",
    "import dataset_location\n",
    "import pytorch3d\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.ops import knn_points\n",
    "import mcubes\n",
    "import utils_vox\n",
    "import matplotlib.pyplot as plt \n",
    "from utils import get_mesh_renderer, get_points_renderer\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "\n",
    "def voxel_grid_visualization(input):\n",
    "\n",
    "\n",
    "    num_frames = 20\n",
    "    voxel_size = 20\n",
    "    max_value = 1.0\n",
    "    min_value = -1.0\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    vertices, faces = mcubes.marching_cubes(input.detach().cpu().squeeze().numpy(), 0.3)\n",
    "    vertices = torch.tensor(vertices).float()\n",
    "    faces = torch.tensor(faces.astype(int))\n",
    "\n",
    "    color1 = torch.tensor([1.0, 0.0, 0.0]).to(device)\n",
    "    color2 = torch.tensor([0.0,1.0, 1.0]).to(device)\n",
    "\n",
    "    vertices = (vertices / voxel_size) * (max_value - min_value) + min_value    \n",
    "    vertices = vertices.unsqueeze(0)  # (N_v, 3) -> (1, N_v, 3)\n",
    "    faces = faces.unsqueeze(0)\n",
    "\n",
    "    z_min = vertices[:,:,2].min()\n",
    "    z_max = vertices[:,:,2].max()\n",
    "    gradient = (vertices[:, :, 2] - z_min) / (z_max - z_min)\n",
    "    retextured = gradient[:, :, None] * color2 + (1 - gradient[:, :, None]) * color1\n",
    "\n",
    "    textures = pytorch3d.renderer.TexturesVertex(retextured)\n",
    "    lights = pytorch3d.renderer.PointLights(location=[[0, 0.0, 3.0]], device=device)\n",
    "    mesh = pytorch3d.structures.Meshes(verts=vertices, faces=faces, textures=textures).to(device)\n",
    "    renderer = get_mesh_renderer(image_size=512, device=device)\n",
    "\n",
    "    my_images = []\n",
    "    for i in range(num_frames):\n",
    "        dist = 3.0\n",
    "        elev = 0\n",
    "        azim = 360 * i / num_frames\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(dist, elev, azim, device=device)\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "        rend = renderer(mesh, cameras=cameras)\n",
    "        rend = rend[0, ..., :3].cpu().numpy()\n",
    "        frame = Image.fromarray((rend * 255).astype(np.uint8))\n",
    "        my_images.append(np.array(frame))\n",
    "    imageio.mimsave(\"output/voxel_grid.gif\", my_images, fps=10)\n",
    "\n",
    "\n",
    "\n",
    "def point_cloud_visualization(input):\n",
    "\n",
    "    image_size= 512\n",
    "    background_color=(1, 1, 1)\n",
    "    num_frames = 20\n",
    "\n",
    "    renderer = get_points_renderer(image_size=image_size, background_color=background_color)\n",
    " \n",
    "    normalized = (input - input.min()) / (input.max() - input.min())\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    color1 = torch.tensor([1.0, 0.0, 0.0]).to(device)\n",
    "    color2 = torch.tensor([0.0,1.0, 1.0]).to(device)\n",
    "    retextured = normalized[:, :, None] * color2 + (1 - normalized[:, :, None]) * color1\n",
    "    retextured=retextured.squeeze(0).permute(1,0,2)\n",
    "\n",
    "    point_cloud = pytorch3d.structures.Pointclouds(points=input, features=retextured)\n",
    " \n",
    "    my_images = []\n",
    "    for i in range(num_frames):\n",
    "        dist = 3.0\n",
    "        elev = 0\n",
    "        azim = 360 * i / num_frames\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(dist, elev, azim, device=device)\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "        rend = renderer(point_cloud, cameras=cameras)\n",
    "        rend = rend[0, ..., :3].cpu().numpy()\n",
    "        frame = Image.fromarray((rend * 255).astype(np.uint8))\n",
    "        my_images.append(np.array(frame))\n",
    "    imageio.mimsave(\"output/point_cloud.gif\", my_images, fps=10)\n",
    "\n",
    "\n",
    "\n",
    "def mesh_visualization(input):\n",
    "    \n",
    "    num_frames = 20\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    vertices = input.verts_packed().to(device)\n",
    "    faces = input.faces_packed().to(device)\n",
    "\n",
    "    color1 = torch.tensor([1.0, 0.0, 0.0]).to(device)\n",
    "    color2 = torch.tensor([0.0,1.0, 1.0]).to(device)\n",
    "\n",
    "\n",
    "    vertices = vertices.unsqueeze(0)  # (N_v, 3) -> (1, N_v, 3)\n",
    "    faces = faces.unsqueeze(0)  # (N_f, 3) -> (1, N_f, 3)\n",
    "    z_min = vertices[:,:,2].min()\n",
    "    z_max = vertices[:,:,2].max()\n",
    "    gradient = (vertices[:, :, 2] - z_min) / (z_max - z_min)\n",
    "    retextured = gradient[:, :, None] * color2 + (1 - gradient[:, :, None]) * color1\n",
    "\n",
    "    textures = pytorch3d.renderer.TexturesVertex(retextured)\n",
    "    mesh = pytorch3d.structures.Meshes(\n",
    "        verts=vertices,\n",
    "        faces=faces,\n",
    "        textures=textures\n",
    "    )\n",
    "    renderer = get_mesh_renderer(image_size=512, device=device)\n",
    "    lights = pytorch3d.renderer.PointLights(location=[[0.0, 0.0, 3.0]], device=device)\n",
    "\n",
    "    my_images = []\n",
    "    for i in range(num_frames):\n",
    "        dist = 3.0\n",
    "        elev = 0\n",
    "        azim = 360 * i / num_frames\n",
    "        R, T = pytorch3d.renderer.look_at_view_transform(dist, elev, azim, device=device)\n",
    "        cameras = pytorch3d.renderer.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "        rend = renderer(mesh, cameras=cameras, lights=lights)\n",
    "        rend = rend[0, ..., :3].cpu().numpy()\n",
    "        frame = Image.fromarray((rend * 255).astype(np.uint8))\n",
    "        my_images.append(np.array(frame))\n",
    "    imageio.mimsave(\"output/mesh.gif\", my_images, fps=10)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
